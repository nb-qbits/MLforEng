{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6946cea3-8d8f-406b-9103-cff0ddd7eaf7",
   "metadata": {},
   "source": [
    "Run on laptop: to validate your local Python + venv setup.\n",
    "\n",
    "Run on OpenShift AI: to confirm the cloned repo and Python environment are ready inside the workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595aa766-23d3-4dd7-a31a-77d9e1f808cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Python environment ===\n",
      "Python executable: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng/.venv/bin/python3.13\n",
      "Python version   : 3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "Platform         : macOS-26.1-arm64-arm-64bit-Mach-O\n",
      "\n",
      "Assumed project root: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng/workshops/00_overview\n",
      "Contents: ['00_overview.ipynb', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "# Basic environment summary\n",
    "import sys\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== Python environment ===\")\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version   :\", sys.version)\n",
    "print(\"Platform         :\", platform.platform())\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(\"\\nAssumed project root:\", project_root)\n",
    "print(\"Contents:\", [p.name for p in project_root.iterdir()][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fb2556-c835-4a7f-a90f-24a503a75307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== venv & Python version check ===\n",
      "`.venv` directory exists: False\n",
      "Current Python executable: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng/.venv/bin/python3.13\n",
      "Current Python version   : 3.13.5\n",
      "\n",
      "❌ WARNING: Expected Python 3.11.\n",
      "   Please recreate the venv with:\n",
      "   python3.11 -m venv .venv && source .venv/bin/activate\n"
     ]
    }
   ],
   "source": [
    "# Check that we’re inside the .venv & on Python 3.11\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== venv & Python version check ===\")\n",
    "\n",
    "venv_dir = Path(\".venv\")\n",
    "print(\"`.venv` directory exists:\", venv_dir.exists())\n",
    "\n",
    "print(\"Current Python executable:\", sys.executable)\n",
    "print(\"Current Python version   :\", sys.version.split()[0])\n",
    "\n",
    "major, minor = sys.version_info[:2]\n",
    "if major == 3 and minor == 11:\n",
    "    print(\"\\n✅ OK: Python 3.11 is active.\")\n",
    "else:\n",
    "    print(\"\\n❌ WARNING: Expected Python 3.11.\")\n",
    "    print(\"   Please recreate the venv with:\")\n",
    "    print(\"   python3.11 -m venv .venv && source .venv/bin/activate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7813294c-11b5-45f7-a68a-9b567452e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Import mlforeng ===\n",
      "❌ ERROR: Could not import mlforeng\n",
      "Exception: ModuleNotFoundError(\"No module named 'mlforeng'\")\n",
      "\n",
      "Hints:\n",
      "- Make sure you're running this notebook from the MLforEng repo root.\n",
      "- Make sure `.venv` is activated.\n"
     ]
    }
   ],
   "source": [
    "# Check core workshop package (mlforeng)\n",
    "print(\"=== Import mlforeng ===\")\n",
    "\n",
    "try:\n",
    "    import mlforeng\n",
    "    print(\"✅ OK: mlforeng imported successfully.\")\n",
    "    print(\"mlforeng module path:\", mlforeng.__file__)\n",
    "except Exception as e:\n",
    "    print(\"❌ ERROR: Could not import mlforeng\")\n",
    "    print(\"Exception:\", repr(e))\n",
    "    print(\"\\nHints:\")\n",
    "    print(\"- Make sure you're running this notebook from the MLforEng repo root.\")\n",
    "    print(\"- Make sure `.venv` is activated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f801bf79-1208-4516-9855-788db8d1daec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM dependency check (datasets, pyarrow, dm-tree) ===\n",
      "❌ datasets not available: ModuleNotFoundError(\"No module named 'datasets'\")\n",
      "   Try: pip install 'datasets>=2.18.0'\n",
      "❌ pyarrow not available: ModuleNotFoundError(\"No module named 'pyarrow'\")\n",
      "   Try: pip install 'pyarrow>=12.0.0'\n",
      "❌ dm-tree (module `tree`) not available: ModuleNotFoundError(\"No module named 'tree'\")\n",
      "   Try: pip install dm-tree\n",
      "\n",
      "⚠️ Fix the errors above, then re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# Check LLM deps: datasets, pyarrow, dm-tree\n",
    "\n",
    "\n",
    "print(\"=== LLM dependency check (datasets, pyarrow, dm-tree) ===\")\n",
    "\n",
    "problems = False\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"✅ datasets imported (version {datasets.__version__})\")\n",
    "except Exception as e:\n",
    "    problems = True\n",
    "    print(\"❌ datasets not available:\", repr(e))\n",
    "    print(\"   Try: pip install 'datasets>=2.18.0'\")\n",
    "\n",
    "try:\n",
    "    import pyarrow\n",
    "    print(f\"✅ pyarrow imported (version {pyarrow.__version__})\")\n",
    "except Exception as e:\n",
    "    problems = True\n",
    "    print(\"❌ pyarrow not available:\", repr(e))\n",
    "    print(\"   Try: pip install 'pyarrow>=12.0.0'\")\n",
    "\n",
    "try:\n",
    "    import tree\n",
    "    print(\"✅ dm-tree (module `tree`) imported\")\n",
    "except Exception as e:\n",
    "    problems = True\n",
    "    print(\"❌ dm-tree (module `tree`) not available:\", repr(e))\n",
    "    print(\"   Try: pip install dm-tree\")\n",
    "\n",
    "if not problems:\n",
    "    print(\"\\n✅ LLM base dependencies look good.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Fix the errors above, then re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4042aba5-ada7-496e-bbc7-4b9d2c30a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM helper import test ===\n",
      "❌ ERROR importing mlforeng.llm_finetune.create_dataset\n",
      "Exception: ModuleNotFoundError(\"No module named 'mlforeng'\")\n",
      "\n",
      "Check that:\n",
      "- mlforeng/llm_finetune/__init__.py only imports `create_dataset`\n",
      "- LLM dependencies were installed in this venv.\n"
     ]
    }
   ],
   "source": [
    "# Import LLM helper module (mlforeng.llm_finetune.create_dataset)\n",
    "\n",
    "print(\"=== LLM helper import test ===\")\n",
    "\n",
    "try:\n",
    "    from mlforeng.llm_finetune import create_dataset\n",
    "    print(\"✅ Imported mlforeng.llm_finetune.create_dataset OK\")\n",
    "except Exception as e:\n",
    "    print(\"❌ ERROR importing mlforeng.llm_finetune.create_dataset\")\n",
    "    print(\"Exception:\", repr(e))\n",
    "    print(\"\\nCheck that:\")\n",
    "    print(\"- mlforeng/llm_finetune/__init__.py only imports `create_dataset`\")\n",
    "    print(\"- LLM dependencies were installed in this venv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f183546-a097-48dc-8e87-b1574599bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPTIONAL: GSM8K dataset JSONL creation test ===\n",
      "This may download ~a few MB from Hugging Face and write JSONL under artifacts/llm_datasets\n",
      "❌ ERROR while creating GSM8K JSONL\n",
      "Exception: ModuleNotFoundError(\"No module named 'mlforeng'\")\n",
      "\n",
      "Check network access and your Hugging Face rate limits / HF_TOKEN if needed.\n"
     ]
    }
   ],
   "source": [
    "# Optional: quick dataset creation smoke test\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== OPTIONAL: GSM8K dataset JSONL creation test ===\")\n",
    "print(\"This may download ~a few MB from Hugging Face and write JSONL under artifacts/llm_datasets\")\n",
    "\n",
    "try:\n",
    "    from mlforeng.llm_finetune import create_dataset\n",
    "\n",
    "    out_dir = create_dataset.gsm8k_qa_no_tokens_template()\n",
    "    out_dir = Path(out_dir)\n",
    "\n",
    "    print(\"✅ Dataset template function ran.\")\n",
    "    print(\"Output directory:\", out_dir)\n",
    "    print(\"Files:\", [p.name for p in out_dir.glob(\"*.jsonl\")])\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"⏹️  Aborted by user.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ ERROR while creating GSM8K JSONL\")\n",
    "    print(\"Exception:\", repr(e))\n",
    "    print(\"\\nCheck network access and your Hugging Face rate limits / HF_TOKEN if needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a9964-3d52-4f37-85c9-05c09d74b46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
