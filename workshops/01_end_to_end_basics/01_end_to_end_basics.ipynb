{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c28c83-b290-4945-b699-33a92d589f85",
   "metadata": {},
   "source": [
    "# MLforEng – Module 01: End-to-End Basics\n",
    "\n",
    "In this module we will:\n",
    "\n",
    "1. Train a model using the `mlforeng` package\n",
    "2. Save the trained model as an artifact\n",
    "3. Load the saved model and run predictions in Python\n",
    "4. (Optional) Call the HTTP serving API for the same model\n",
    "\n",
    "This module is independent — you don't need to run any other notebooks first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700dadf7-1fa9-47d4-ae8a-101b1055a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng\n",
      "CWD: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Assume this notebook is in MLforEng/workshops/01_end_to_end_basics\n",
    "project_root = Path.cwd().parents[1]   # go up from workshops/01_end_to_end_basics -> MLforEng\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "os.chdir(project_root)\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "from mlforeng.train import TrainConfig, train\n",
    "from mlforeng.predict import load_trained_model, predict_array\n",
    "from mlforeng.data import load_example_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a635930b-c769-40f1-82d5-e9b2df616797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(dataset='synthetic', model_name='logreg', n_samples=500, n_features=10, test_size=0.2, save_model_name='module01_logreg')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure Training\n",
    "config = TrainConfig(\n",
    "    model_name=\"logreg\",          # ALgorithm\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    test_size=0.2,\n",
    "    save_model_name=\"module01_logreg\",  # Model Name is module01_logreg placed under artifacts/pretrained\n",
    ")\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543bf150-ad6b-4062-ba75-17561cec36f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '/Users/vgrover/Downloads/software/AIWorkshops/MLforEng/artifacts/pretrained/module01_logreg/model.joblib',\n",
       " 'config': {'dataset': 'synthetic',\n",
       "  'model_name': 'logreg',\n",
       "  'n_samples': 500,\n",
       "  'n_features': 10,\n",
       "  'test_size': 0.2,\n",
       "  'save_model_name': 'module01_logreg'},\n",
       " 'metrics': {'accuracy': 0.86},\n",
       " 'extra': {'dataset': 'synthetic', 'n_samples': 500, 'n_features': 10}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model. Generate data → Split → Train → Evaluate → Save\n",
    "results = train(config)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a9e82f-b2f3-4370-bfed-d17833189a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cli_logreg_test', '.DS_Store', 'commscom_rf_baseline', 'cli_rf_test', 'default_model', 'nb_logreg_test', 'commscom_rf_tuned', 'commscom_logreg_baseline', 'module01_logreg', 'quickstart_model']\n",
      "['model.joblib', 'meta.json']\n"
     ]
    }
   ],
   "source": [
    "# Verify artifacts\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"artifacts/pretrained\"))\n",
    "print(os.listdir(\"artifacts/pretrained/module01_logreg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82fe9d1-a32e-4da1-aa5c-8a4994067fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from: /Users/vgrover/Downloads/software/AIWorkshops/MLforEng/artifacts/pretrained/module01_logreg\n",
      "Meta keys: dict_keys(['config', 'metrics', 'extra'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'dataset': 'synthetic',\n",
       "  'model_name': 'logreg',\n",
       "  'n_samples': 500,\n",
       "  'n_features': 10,\n",
       "  'test_size': 0.2,\n",
       "  'save_model_name': 'module01_logreg'},\n",
       " 'metrics': {'accuracy': 0.86},\n",
       " 'extra': {'dataset': 'synthetic', 'n_samples': 500, 'n_features': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load persisted model. Deserializes model from disk back into memory and Access metadata (config, metrics)\n",
    "loaded = load_trained_model(\"module01_logreg\")\n",
    "\n",
    "print(\"Loaded from:\", loaded.path)\n",
    "print(\"Meta keys:\", loaded.meta.keys())\n",
    "loaded.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b645894-d850-4094-96aa-60af6e934279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out how many features the model expects\n",
    "cfg = loaded.meta.get(\"config\", {})\n",
    "n_features = cfg.get(\"n_features\", 10)\n",
    "\n",
    "# Generate a fresh synthetic test set with the same feature count\n",
    "splits = load_example_dataset(\n",
    "    n_samples=200,\n",
    "    n_features=n_features,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "X_test = splits.X_test[:5]\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4674d989-d507-45c5-a0f4-cc95ab5626f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Batch prediction\n",
    "preds = predict_array(loaded, X_test)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd26ffa-8113-4ff7-984c-36f8ec99ddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " {'model_name': 'cli_logreg_test',\n",
       "  'dataset': None,\n",
       "  'n_instances': 3,\n",
       "  'predictions': [1, 1, 1]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional Step : Needs API server\n",
    "# Pre-requisite is to run $python -m mlforeng.serve in your terminal \n",
    "# or $ uvicorn mlforeng.serve:app --host 0.0.0.0 --port 8000\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Take a few samples from our test set and send them to the API\n",
    "instances = X_test[:3].tolist()\n",
    "\n",
    "payload = {\"instances\": instances}\n",
    "resp = requests.post(\"http://127.0.0.1:8000/predict\", json=payload)\n",
    "resp.status_code, resp.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc48f9-4104-4c3b-819e-869328c2b377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
