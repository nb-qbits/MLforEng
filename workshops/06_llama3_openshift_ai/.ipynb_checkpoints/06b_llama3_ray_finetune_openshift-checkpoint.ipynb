{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44abc995-78c7-4b6b-a34f-af95e2335ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== oc whoami ===\n",
      "system:serviceaccount:ray-finetune-llm-deepspeed002:notebook\n",
      "\n",
      "=== RayCluster status ===\n",
      "RayCluster found. GPU toleration on head: False\n"
     ]
    }
   ],
   "source": [
    "import subprocess, json\n",
    "\n",
    "NS = \"ray-finetune-llm-deepspeed002\"\n",
    "\n",
    "def run(cmd):\n",
    "    return subprocess.check_output(cmd, text=True).strip()\n",
    "\n",
    "print(\"=== oc whoami ===\")\n",
    "print(run([\"oc\", \"whoami\"]))\n",
    "\n",
    "print(\"\\n=== RayCluster status ===\")\n",
    "try:\n",
    "    data = json.loads(run([\"oc\", \"get\", \"raycluster\", \"ray\", \"-n\", NS, \"-o\", \"json\"]))\n",
    "    head_tols = data[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"].get(\"tolerations\", [])\n",
    "    has_gpu_tol = any(\n",
    "        t.get(\"key\") == \"nvidia.com/gpu\" and t.get(\"effect\") == \"NoSchedule\"\n",
    "        for t in head_tols\n",
    "    )\n",
    "    print(\"RayCluster found. GPU toleration on head:\", has_gpu_tol)\n",
    "except Exception as e:\n",
    "    print(\"❌ RayCluster not ready. Please contact your instructor.\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc8fdd33-35aa-464d-ab6b-4c51e525fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insecure request warnings have been disabled\n",
      "Authenticated to OpenShift API: https://172.30.0.1:443\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from codeflare_sdk import TokenAuthentication\n",
    "\n",
    "token = subprocess.check_output([\"oc\", \"whoami\", \"-t\"]).decode().strip()\n",
    "server = subprocess.check_output(\n",
    "    [\"oc\", \"whoami\", \"--show-server=true\"]\n",
    ").decode().strip()\n",
    "\n",
    "auth = TokenAuthentication(\n",
    "    token=token,\n",
    "    server=server,\n",
    "    skip_tls=True,  # set True if your cluster TLS is self-signed and noisy\n",
    ")\n",
    "auth.login()\n",
    "print(\"Authenticated to OpenShift API:\", server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9e92a19-8afc-4889-8958-cfede27ec052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ray dashboard at: http://ray-head-svc.ray-finetune-llm-deepspeed002.svc.cluster.local:8265\n"
     ]
    }
   ],
   "source": [
    "from ray.job_submission import JobSubmissionClient\n",
    "\n",
    "NS = \"ray-finetune-llm-deepspeed002\"\n",
    "ray_head_addr = f\"http://ray-head-svc.{NS}.svc.cluster.local:8265\"\n",
    "\n",
    "client = JobSubmissionClient(ray_head_addr)\n",
    "print(\"Connected to Ray dashboard at:\", ray_head_addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204a90fb-da94-426a-8c0c-3a0c61b01086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6775bf-d922-4a13-a32c-eb66c3df2ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /opt/app-root/lib64/python3.11/site-packages (1.26.4)\n",
      "Collecting pyarrow==15.0.2\n",
      "  Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting datasets==2.18.0\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (0.7)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (3.12.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (1.2.1)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets==2.18.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets==2.18.0) (1.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->datasets==2.18.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.19.0->datasets==2.18.0) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets==2.18.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets==2.18.0) (2025.2)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.4->datasets==2.18.0) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.4->datasets==2.18.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.19.4->datasets==2.18.0) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.11/site-packages (from typer-slim->huggingface-hub>=0.19.4->datasets==2.18.0) (8.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.19.4->datasets==2.18.0) (1.3.1)\n",
      "Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m194.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "Installing collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 22.0.0\n",
      "    Uninstalling pyarrow-22.0.0:\n",
      "      Successfully uninstalled pyarrow-22.0.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.4.1\n",
      "    Uninstalling datasets-4.4.1:\n",
      "      Successfully uninstalled datasets-4.4.1\n",
      "Successfully installed datasets-2.18.0 pyarrow-15.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade --no-cache-dir \\\n",
    "    \"numpy==1.26.4\" \\\n",
    "    \"pyarrow==15.0.2\" \\\n",
    "    \"datasets==2.18.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30c26b-d439-4d74-b3fe-d9e84db29a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets>=2.18.0 in /opt/app-root/lib64/python3.11/site-packages (2.18.0)\n",
      "Collecting datasets>=2.18.0\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/app-root/lib64/python3.11/site-packages (15.0.2)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (1.26.4)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (1.2.1)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets>=2.18.0) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (3.12.13)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx<1.0.0->datasets>=2.18.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.11/site-packages (from httpx<1.0.0->datasets>=2.18.0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1.0.0->datasets>=2.18.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib64/python3.11/site-packages (from httpx<1.0.0->datasets>=2.18.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.18.0) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.18.0) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.18.0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.18.0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.18.0) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets>=2.18.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets>=2.18.0) (1.26.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets>=2.18.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets>=2.18.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets>=2.18.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.18.0) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.18.0) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.11/site-packages (from anyio->httpx<1.0.0->datasets>=2.18.0) (1.3.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.11/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets>=2.18.0) (8.2.1)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m157.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 15.0.2\n",
      "    Uninstalling pyarrow-15.0.2:\n",
      "      Successfully uninstalled pyarrow-15.0.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.18.0\n",
      "    Uninstalling datasets-2.18.0:\n",
      "      Successfully uninstalled datasets-2.18.0\n",
      "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the training and evaluation datasets.\n",
    "# This can be run only once.\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade --no-cache-dir \"datasets>=2.18.0\" \"pyarrow>=12.0.0\"\n",
    "from mlforeng.llm_finetune import create_dataset\n",
    "# import create_dataset\n",
    "create_dataset.gsm8k_qa_no_tokens_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e460788-90a2-48a6-b7af-5217177fd432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using server: https://172.30.0.1:443\n",
      "Insecure request warnings have been disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Logged into https://172.30.0.1:443'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from codeflare_sdk import TokenAuthentication\n",
    "\n",
    "# Ask the oc CLI for your current token and API server\n",
    "token = subprocess.check_output([\"oc\", \"whoami\", \"-t\"]).decode().strip()\n",
    "server = subprocess.check_output(\n",
    "    [\"oc\", \"whoami\", \"--show-server=true\"]\n",
    ").decode().strip()\n",
    "\n",
    "print(\"Using server:\", server)\n",
    "\n",
    "# If your cluster uses self-signed certs, skip_tls=True avoids SSL errors.\n",
    "# If you have proper certs, set skip_tls=False instead.\n",
    "auth = TokenAuthentication(\n",
    "    token=token,\n",
    "    server=server,\n",
    "    skip_tls=True,   # or False if TLS is fully trusted\n",
    ")\n",
    "auth.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d340f86-1a04-48d3-a5e7-067faecfc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml resources loaded for ray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3974d9cac04bbd89f565db75fee470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Cluster Up', icon='play', style=ButtonStyle(), tooltip='Crea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f81b1610ebb48d68e6ecb344c053668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<codeflare_sdk.ray.cluster.cluster.Cluster at 0x7fd9cf88e9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codeflare_sdk import Cluster, ClusterConfiguration\n",
    "\n",
    "cluster_cfg = ClusterConfiguration(\n",
    "    name=\"ray\",\n",
    "    namespace=\"ray-finetune-llm-deepspeed002\",   # your DS project namespace\n",
    "\n",
    "    # Small, schedulable cluster: head + 2 workers = 3 GPUs total\n",
    "    num_workers=2,\n",
    "\n",
    "    head_cpu_requests=4,\n",
    "    head_cpu_limits=4,\n",
    "    head_memory_requests=24,   # GiB\n",
    "    head_memory_limits=24,\n",
    "\n",
    "    worker_cpu_requests=4,\n",
    "    worker_cpu_limits=4,\n",
    "    worker_memory_requests=24,\n",
    "    worker_memory_limits=24,\n",
    "\n",
    "    image=\"quay.io/rhoai/ray:2.35.0-py311-cu121-torch24-fa26\",\n",
    "\n",
    "    # 1 GPU on head + each worker\n",
    "    head_extended_resource_requests={\"nvidia.com/gpu\": 1},\n",
    "    worker_extended_resource_requests={\"nvidia.com/gpu\": 1},\n",
    "\n",
    "    # REQUIRED by the Kueue validating policy\n",
    "    labels={\"kueue.x-k8s.io/queue-name\": \"local-queue-ray\"},\n",
    ")\n",
    "\n",
    "cluster = Cluster(cluster_cfg)\n",
    "cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee11013-8646-4cda-94a2-f8e731baa1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Cluster: 'ray' has successfully been applied. For optimal resource management, you should delete this Ray Cluster when no longer in use.\n"
     ]
    }
   ],
   "source": [
    "# Create the Ray cluster\n",
    "cluster.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccda92-a0f0-4845-a13c-6aa735e75d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7caa2749-e9e1-4ede-852e-019931fdd1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: ray\n",
      "Namespace: ray-finetune-llm-deepspeed002\n",
      "Ray URL: http://ray-head-svc.ray-finetune-llm-deepspeed002.svc.cluster.local:8265\n",
      "✓ Client connected!\n",
      "✓ Found 0 existing jobs\n"
     ]
    }
   ],
   "source": [
    "from ray.job_submission import JobSubmissionClient\n",
    "\n",
    "# Use cluster config (you already have this from earlier cells)\n",
    "namespace = cluster.config.namespace\n",
    "cluster_name = cluster.config.name\n",
    "\n",
    "# Construct URL dynamically\n",
    "ray_url = f\"http://ray-head-svc.{namespace}.svc.cluster.local:8265\"\n",
    "\n",
    "print(f\"Cluster: {cluster_name}\")\n",
    "print(f\"Namespace: {namespace}\")\n",
    "print(f\"Ray URL: {ray_url}\")\n",
    "\n",
    "# Create client\n",
    "client = JobSubmissionClient(ray_url)\n",
    "print(\"✓ Client connected!\")\n",
    "\n",
    "# Verify\n",
    "jobs = client.list_jobs()\n",
    "print(f\"✓ Found {len(jobs)} existing jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage configuration\n",
    "storage_path = '/opt/app-root/src'\n",
    "\n",
    "# The S3 bucket where to store checkpoint.\n",
    "# It can be set manually, otherwise it's retrieved from configured the data connection.\n",
    "s3_bucket = ''  # Empty string for local storage\n",
    "\n",
    "# Comment out S3 logic - keep it simple\n",
    "# if not s3_bucket:\n",
    "#     s3_bucket = os.environ.get('AWS_S3_BUCKET')\n",
    "# if s3_bucket:\n",
    "#     storage_path = f's3://{s3_bucket}'\n",
    "\n",
    "print(f\"Using local storage: {storage_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2be5d8-66c7-46e2-ba3b-fa2f8a03b27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submit Ray job\n",
    "submission_id = client.submit_job(\n",
    "    entrypoint=\"python ray_finetune_llm_deepspeed.py \"\n",
    "               \"--model-name=meta-llama/Meta-Llama-3.1-8B \"\n",
    "               \"--lora \"\n",
    "               \"--num-devices=2 \"\n",
    "               \"--num-epochs=1 \"\n",
    "               \"--max-steps=5 \"\n",
    "               \"--ds-config=./deepspeed_configs/zero_3_offload_optim_param.json \"\n",
    "               f\"--storage-path={storage_path}/ray_finetune_llm_deepspeed/ \"\n",
    "               \"--batch-size-per-device=1 \"\n",
    "               \"--eval-batch-size-per-device=1 \",\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            # Set the following variables if using AWS S3 as storage\n",
    "            # 'AWS_ACCESS_KEY_ID': os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "            # 'AWS_SECRET_ACCESS_KEY': os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "            # 'AWS_DEFAULT_REGION': os.environ.get('AWS_DEFAULT_REGION'),\n",
    "            'HF_HOME': f'{storage_path}/.cache'\n",
    "        },\n",
    "        'pip': 'requirements.txt',\n",
    "        'working_dir': './',\n",
    "        \"excludes\": [\"/docs/\", \"*.ipynb\", \"*.md\"]\n",
    "    },\n",
    ")\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdfd0f-9284-42ed-8d0c-623910593cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Monitoring training progress...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "prev_log_length = 0\n",
    "for i in range(60):  # Check for 60 iterations (30 minutes)\n",
    "    logs = client.get_job_logs(submission_id)\n",
    "    lines = logs.split('\\n')\n",
    "    \n",
    "    # Only show new lines\n",
    "    if len(lines) > prev_log_length:\n",
    "        new_lines = lines[prev_log_length:]\n",
    "        for line in new_lines:\n",
    "            if any(keyword in line.lower() for keyword in ['step', 'epoch', 'loss', 'loading', 'error', 'training']):\n",
    "                print(line)\n",
    "        prev_log_length = len(lines)\n",
    "    \n",
    "    status = client.get_job_status(submission_id)\n",
    "    if status in [\"SUCCEEDED\", \"FAILED\", \"STOPPED\"]:\n",
    "        print(f\"\\n✓ Job finished with status: {status}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  # Check every 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8476f19b-1d51-44f5-8889-c5b01ed36343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.stop_job(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456f161-5122-4057-a5ac-f7f6b38651ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7673e-ee7e-47df-804a-9fa3c3b1d492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
