{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a65a54d-41d9-4cef-8e5f-06eda7a9918a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "1. OpenShift User:\n",
      "   system:serviceaccount:ray-finetune-llm-deepspeed002:notebook\n",
      "\n",
      "2. RayCluster Status:\n",
      "   State: ready\n",
      "   Workers: 6\n",
      "   GPU toleration: True\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Environment check complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess, json\n",
    "\n",
    "NS = \"ray-finetune-llm-deepspeed002\"\n",
    "\n",
    "def run(cmd):\n",
    "    return subprocess.check_output(cmd, text=True).strip()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. OpenShift User:\")\n",
    "print(f\"   {run(['oc', 'whoami'])}\")\n",
    "\n",
    "print(\"\\n2. RayCluster Status:\")\n",
    "try:\n",
    "    data = json.loads(run([\"oc\", \"get\", \"raycluster\", \"ray\", \"-n\", NS, \"-o\", \"json\"]))\n",
    "    state = data.get(\"status\", {}).get(\"state\", \"unknown\")\n",
    "    workers = data.get(\"status\", {}).get(\"availableWorkerReplicas\", 0)\n",
    "    print(f\"   State: {state}\")\n",
    "    print(f\"   Workers: {workers}\")\n",
    "    \n",
    "    head_tols = data[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"].get(\"tolerations\", [])\n",
    "    has_gpu = any(t.get(\"key\") == \"nvidia.com/gpu\" for t in head_tols)\n",
    "    print(f\"   GPU toleration: {has_gpu}\")\n",
    "    \n",
    "    if state != \"ready\":\n",
    "        print(\"   ‚ö†Ô∏è  Cluster not ready yet\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Environment check complete\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b63bb1ff-c51f-4f0c-8931-0b04042a2a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insecure request warnings have been disabled\n",
      "‚úÖ Authenticated to: https://172.30.0.1:443\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from codeflare_sdk import TokenAuthentication\n",
    "\n",
    "token = subprocess.check_output([\"oc\", \"whoami\", \"-t\"]).decode().strip()\n",
    "server = subprocess.check_output([\"oc\", \"whoami\", \"--show-server=true\"]).decode().strip()\n",
    "\n",
    "auth = TokenAuthentication(\n",
    "    token=token,\n",
    "    server=server,\n",
    "    skip_tls=True\n",
    ")\n",
    "auth.login()\n",
    "\n",
    "print(f\"‚úÖ Authenticated to: {server}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae7e91d5-adab-4b72-becc-cd3748965378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir exists: True\n",
      "has config.json: True\n",
      "files: ['.cache', '.gitattributes', 'LICENSE.md', 'README.md', 'config.json', 'flax_model.msgpack', 'generation_config.json', 'merges.txt', 'pytorch_model.bin', 'special_tokens_map.json', 'tf_model.h5', 'tokenizer_config.json', 'vocab.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "p=\"/opt/app-root/src/models/facebook/opt-125m\"\n",
    "print(\"dir exists:\", os.path.isdir(p))\n",
    "if os.path.isdir(p):\n",
    "    print(\"has config.json:\", os.path.exists(os.path.join(p,\"config.json\")))\n",
    "    print(\"files:\", sorted(os.listdir(p))[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53f89474-d901-4d30-be0c-201604f080a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "‚úÖ Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade --quiet --no-cache-dir \\\n",
    "    \"numpy==1.26.4\" \\\n",
    "    \"pyarrow==15.0.2\" \\\n",
    "    \"datasets==2.18.0\"\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22097bcb-e9e0-439d-8ee6-3d76c73fe36f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üì¶ Model:\n",
      "   ID: Qwen/Qwen2.5-0.5B\n",
      "   Type: HuggingFace\n",
      "\n",
      "üìä Dataset:\n",
      "   Type: jsonl\n",
      "   Train: /opt/app-root/src/MLforEng/artifacts/datasets/commscom_llama_prompts.jsonl\n",
      "   Eval: /opt/app-root/src/MLforEng/artifacts/datasets/commscom_llama_prompts.jsonl\n",
      "   ‚úÖ File found: 500 examples\n",
      "\n",
      "‚öôÔ∏è  Training:\n",
      "   Max steps: 30\n",
      "   Epochs: 1\n",
      "   Batch size: 2\n",
      "   Max sequence: 512\n",
      "   Learning rate: 2e-05\n",
      "   Precision: BF16\n",
      "\n",
      "üíæ Output:\n",
      "   /opt/app-root/src/models/llama-finetuned\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# WORKING_DIR = \"/opt/app-root/src/MLforEng\"\n",
    "\n",
    "# Option 1: Use local uploaded model (RECOMMENDED - no download needed)\n",
    "# LLM_MODEL_ID = \"/opt/app-root/src/models/llama-3.2-1b-instruct\"\n",
    "\n",
    "# LLM_MODEL_ID = \"/opt/app-root/src/models/facebook/opt-125m\"\n",
    "\n",
    "# LLM_MODEL_ID = \"facebook/opt-125m\"\n",
    "\n",
    "# LLM_MODEL_ID = \"gpt2\"\n",
    "LLM_MODEL_ID = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "# Option 2: Use HuggingFace model (requires network + token)\n",
    "# LLM_MODEL_ID = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# LLM_MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# HuggingFace token (only needed for gated models like Llama)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"<TOKEN\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET CONFIGURATION  \n",
    "# =============================================================================\n",
    "\n",
    "# Option 1: Use your custom JSONL dataset\n",
    "DATASET_TYPE = \"jsonl\"\n",
    "TRAIN_JSONL = \"/opt/app-root/src/MLforEng/artifacts/datasets/commscom_llama_prompts.jsonl\"  # Relative to working_dir\n",
    "EVAL_JSONL = \"/opt/app-root/src/MLforEng/artifacts/datasets/commscom_llama_prompts.jsonl\"\n",
    "\n",
    "# Option 2: Use GSM8K demo dataset (math problems)\n",
    "# DATASET_TYPE = \"gsm8k\"\n",
    "# TRAIN_JSONL = \"\"  # Not used for gsm8k\n",
    "# EVAL_JSONL = \"\"\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = \"/opt/app-root/src/models/llama-finetuned\"\n",
    "STORAGE_PATH = \"/opt/app-root/src\"\n",
    "\n",
    "# Training hyperparameters\n",
    "MAX_STEPS = 30  # Small for demo; set to 0 to use NUM_TRAIN_EPOCHS\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "TRAIN_BATCH_SIZE = 2  # Can use 2 for 1B models, 1 for 8B\n",
    "EVAL_BATCH_SIZE = 2\n",
    "MAX_SEQ_LENGTH = 512\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_RATIO = 0.03\n",
    "SAVE_STEPS = 30\n",
    "EVAL_STEPS = 30\n",
    "SAVE_TOTAL_LIMIT = 2\n",
    "\n",
    "# Precision (use BF16 for modern GPUs like L4, A100)\n",
    "USE_BF16 = True\n",
    "USE_FP16 = False\n",
    "\n",
    "# =============================================================================\n",
    "# DISPLAY CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüì¶ Model:\")\n",
    "print(f\"   ID: {LLM_MODEL_ID}\")\n",
    "print(f\"   Type: {'Local' if LLM_MODEL_ID.startswith('/') else 'HuggingFace'}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Type: {DATASET_TYPE}\")\n",
    "if DATASET_TYPE == \"jsonl\":\n",
    "    print(f\"   Train: {TRAIN_JSONL}\")\n",
    "    print(f\"   Eval: {EVAL_JSONL}\")\n",
    "    \n",
    "    # Verify file exists\n",
    "    full_path = os.path.join(\"/opt/app-root/src/MLforEng\", TRAIN_JSONL)\n",
    "    if os.path.exists(full_path):\n",
    "        with open(full_path) as f:\n",
    "            num_lines = sum(1 for _ in f)\n",
    "        print(f\"   ‚úÖ File found: {num_lines} examples\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå File not found: {full_path}\")\n",
    "else:\n",
    "    print(f\"   Using GSM8K (will download automatically)\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Training:\")\n",
    "print(f\"   Max steps: {MAX_STEPS}\")\n",
    "print(f\"   Epochs: {NUM_TRAIN_EPOCHS}\")\n",
    "print(f\"   Batch size: {TRAIN_BATCH_SIZE}\")\n",
    "print(f\"   Max sequence: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   Precision: {'BF16' if USE_BF16 else 'FP16' if USE_FP16 else 'FP32'}\")\n",
    "\n",
    "print(f\"\\nüíæ Output:\")\n",
    "print(f\"   {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f629e60a-90d5-4e9c-b134-f476cd2da73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Ray: http://ray-head-svc.ray-finetune-llm-deepspeed002.svc.cluster.local:8265\n",
      "   Existing jobs: 56\n"
     ]
    }
   ],
   "source": [
    "from ray.job_submission import JobSubmissionClient\n",
    "\n",
    "NS = \"ray-finetune-llm-deepspeed002\"\n",
    "ray_dashboard_url = f\"http://ray-head-svc.{NS}.svc.cluster.local:8265\"\n",
    "\n",
    "client = JobSubmissionClient(ray_dashboard_url)\n",
    "\n",
    "# Verify connection\n",
    "jobs = client.list_jobs()\n",
    "print(f\"‚úÖ Connected to Ray: {ray_dashboard_url}\")\n",
    "print(f\"   Existing jobs: {len(jobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8edda3d6-7741-4c3c-b2f6-912260efd856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:25:46,932\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_597d216c3cbfce9c.zip.\n",
      "2025-12-13 15:25:46,933\tINFO packaging.py:576 -- Creating a file package for local module './'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting training job...\n",
      "======================================================================\n",
      "‚úÖ Job submitted successfully!\n",
      "\n",
      "üìã Job ID: raysubmit_gTc7afNCS7x6xzys\n",
      "‚è±Ô∏è  Status: PENDING\n",
      "\n",
      "üí° Monitor in next cell\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitting training job...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build runtime environment\n",
    "runtime_env = {\n",
    "    \"working_dir\": \"./\",\n",
    "    \"pip\": \"requirements.txt\",\n",
    "    \"excludes\": [\"/docs/\", \"*.ipynb\", \"*.md\", \".git/\"],\n",
    "    \"env_vars\": {\n",
    "        # Model\n",
    "        \"LLM_MODEL_ID\": LLM_MODEL_ID,\n",
    "        \"HF_TOKEN\": HF_TOKEN,\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": HF_TOKEN,\n",
    "        \n",
    "        # Dataset\n",
    "        \"DATASET_TYPE\": DATASET_TYPE,\n",
    "        \"TRAIN_JSONL\": TRAIN_JSONL,\n",
    "        \"EVAL_JSONL\": EVAL_JSONL,\n",
    "        \n",
    "        # Training\n",
    "        \"OUTPUT_DIR\": OUTPUT_DIR,\n",
    "        \"MAX_STEPS\": str(MAX_STEPS),\n",
    "        \"NUM_TRAIN_EPOCHS\": str(NUM_TRAIN_EPOCHS),\n",
    "        \"TRAIN_BATCH_SIZE\": str(TRAIN_BATCH_SIZE),\n",
    "        \"EVAL_BATCH_SIZE\": str(EVAL_BATCH_SIZE),\n",
    "        \"MAX_SEQ_LENGTH\": str(MAX_SEQ_LENGTH),\n",
    "        \"GRAD_ACCUM_STEPS\": str(GRAD_ACCUM_STEPS),\n",
    "        \"LEARNING_RATE\": str(LEARNING_RATE),\n",
    "        \"WARMUP_RATIO\": str(WARMUP_RATIO),\n",
    "        \"SAVE_STEPS\": str(SAVE_STEPS),\n",
    "        \"EVAL_STEPS\": str(EVAL_STEPS),\n",
    "        \"SAVE_TOTAL_LIMIT\": str(SAVE_TOTAL_LIMIT),\n",
    "        \"USE_BF16\": \"1\" if USE_BF16 else \"0\",\n",
    "        \"USE_FP16\": \"1\" if USE_FP16 else \"0\",\n",
    "        \n",
    "        # Cache\n",
    "        \"HF_HOME\": f\"{STORAGE_PATH}/.cache\",\n",
    "        \"TRANSFORMERS_CACHE\": f\"{STORAGE_PATH}/.cache/transformers\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Build entrypoint (simple python script call)\n",
    "entrypoint = \"python ray_finetune_simple.py\"\n",
    "\n",
    "try:\n",
    "    submission_id = client.submit_job(\n",
    "        entrypoint=entrypoint,\n",
    "        runtime_env=runtime_env\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Job submitted successfully!\")\n",
    "    print(f\"\\nüìã Job ID: {submission_id}\")\n",
    "    print(f\"‚è±Ô∏è  Status: {client.get_job_status(submission_id)}\")\n",
    "    print(f\"\\nüí° Monitor in next cell\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Submission failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84e5ca48-bd2d-445e-97f4-b2203e09b215",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring training progress...\n",
      "======================================================================\n",
      "[TRAIN] Starting training script\n",
      "[TRAIN] Config:\n",
      "[TRAIN]   Max steps: 30\n",
      "[TRAIN] Loading GSM8K dataset...\n",
      "[TRAIN] Dataset loaded: 7473 train, 1319 eval\n",
      "[TRAIN] Loading model: Qwen/Qwen2.5-0.5B\n",
      "[TRAIN] Training arguments configured\n",
      "[TRAIN] Starting training...\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "{'loss': 1.9064, 'grad_norm': 5.1875, 'learning_rate': 1.4482758620689657e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1662, 'grad_norm': 3.734375, 'learning_rate': 7.586206896551724e-06, 'epoch': 0.02}\n",
      "{'loss': 0.1525, 'grad_norm': 4.71875, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.03}\n",
      "\u001b[A{'eval_loss': 0.46082746982574463, 'eval_runtime': 31.644, 'eval_samples_per_second': 41.682, 'eval_steps_per_second': 20.857, 'epoch': 0.03}\n",
      "{'train_runtime': 53.4075, 'train_samples_per_second': 4.494, 'train_steps_per_second': 0.562, 'train_loss': 0.7417077898979187, 'epoch': 0.03}\n",
      "[TRAIN] Training complete!\n",
      "[TRAIN] Running evaluation...\n",
      "[TRAIN] Evaluation metrics: {\n",
      "  \"eval_loss\": 0.46082746982574463,\n",
      "  \"eval_runtime\": 31.7444,\n",
      "  \"eval_samples_per_second\": 41.551,\n",
      "  \"eval_steps_per_second\": 20.791,\n",
      "  \"epoch\": 0.03211131924003211\n",
      "[TRAIN] Saving model to /opt/app-root/src/models/llama-finetuned\n",
      "[TRAIN] ‚úÖ Training pipeline complete!\n",
      "\n",
      "======================================================================\n",
      "üéâ Training completed successfully!\n",
      "\n",
      "üìÅ Model saved to: /opt/app-root/src/models/llama-finetuned\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Monitoring training progress...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prev_log_length = 0\n",
    "check_interval = 30  # seconds\n",
    "\n",
    "for i in range(60):  # 30 minutes max\n",
    "    logs = client.get_job_logs(submission_id)\n",
    "    lines = logs.split('\\n') if logs else []\n",
    "    \n",
    "    # Show new log lines\n",
    "    if len(lines) > prev_log_length:\n",
    "        new_lines = lines[prev_log_length:]\n",
    "        \n",
    "        keywords = ['step', 'epoch', 'loss', 'loading', 'error', 'training', \n",
    "                   'completed', 'saving', 'eval', 'config']\n",
    "        \n",
    "        for line in new_lines:\n",
    "            if any(kw in line.lower() for kw in keywords):\n",
    "                print(line)\n",
    "        \n",
    "        prev_log_length = len(lines)\n",
    "    \n",
    "    # Check status\n",
    "    status = client.get_job_status(submission_id)\n",
    "    \n",
    "    if status in [\"SUCCEEDED\", \"FAILED\", \"STOPPED\"]:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        if status == \"SUCCEEDED\":\n",
    "            print(\"üéâ Training completed successfully!\")\n",
    "            print(f\"\\nüìÅ Model saved to: {OUTPUT_DIR}\")\n",
    "        elif status == \"FAILED\":\n",
    "            print(\"‚ùå Training failed!\")\n",
    "            print(\"\\nüìã Last 1000 chars of logs:\")\n",
    "            print(logs[-1000:])\n",
    "        else:\n",
    "            print(f\"‚èπÔ∏è  Job stopped\")\n",
    "        print(\"=\" * 70)\n",
    "        break\n",
    "    \n",
    "    # Periodic update\n",
    "    if i % 10 == 0:\n",
    "        elapsed = i * check_interval\n",
    "        print(f\"\\n[{elapsed}s] Status: {status}\")\n",
    "    \n",
    "    time.sleep(check_interval)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Monitoring timeout - job may still be running\")\n",
    "    print(f\"   Current status: {client.get_job_status(submission_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bd470-5fde-4eb4-a68e-c9202995ea84",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
